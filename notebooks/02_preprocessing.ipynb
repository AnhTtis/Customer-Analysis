{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09479c66",
   "metadata": {},
   "source": [
    "# Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3048325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1cdc0",
   "metadata": {},
   "source": [
    "## I. Chuẩn bị dữ liệu để xử lí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7f312",
   "metadata": {},
   "source": [
    "### I.1 Lấy dữ liệu thô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c353c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../data/BankChurners.csv'\n",
    "data = np.genfromtxt(csv_path, delimiter=',', dtype=str, encoding='ascii')\n",
    "\n",
    "# Loại bỏ hai cột cuối không cần thiết\n",
    "data = data[:, :-2]\n",
    "columns = data[0, :]\n",
    "columns = np.char.replace(columns, '\"', '')\n",
    "data = data[1:, :]\n",
    "data = np.char.replace(data, '\"', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c537a7",
   "metadata": {},
   "source": [
    "### I.2 Tạo từ điển để ánh xạ nhanh tên cột với dữ liệu của cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b8b643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo một từ điển để ánh xạ tên cột với chỉ số của chúng\n",
    "dict_data = {'CLIENTNUM': 0, \n",
    "             'Attrition_Flag': 1,\n",
    "             'Customer_Age': 2,\n",
    "             'Gender': 3,\n",
    "             'Dependent_count': 4, \n",
    "             'Education_Level': 5, \n",
    "             'Marital_Status': 6,\n",
    "             'Income_Category': 7, \n",
    "             'Card_Category': 8, \n",
    "             'Months_on_book': 9,\n",
    "             'Total_Relationship_Count': 10, \n",
    "             'Months_Inactive_12_mon': 11, \n",
    "             'Contacts_Count_12_mon': 12,\n",
    "             'Credit_Limit': 13, \n",
    "             'Total_Revolving_Bal': 14, \n",
    "             'Avg_Open_To_Buy': 15, \n",
    "             'Total_Amt_Chng_Q4_Q1': 16,\n",
    "             'Total_Trans_Amt': 17, \n",
    "             'Total_Trans_Ct': 18, \n",
    "             'Total_Ct_Chng_Q4_Q1': 19, \n",
    "             'Avg_Utilization_Ratio': 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd431a",
   "metadata": {},
   "source": [
    "## II. Bỏ những cột không quan trọng trong việc thiết kế mô hình\n",
    "Trong quá trình phân tích dữ lệu thì ta sẽ không sử dụng đến một dữ liệu với những lí do sau:\n",
    "1.  **`Avg_Open_To_Buy`**: Vì có tương quan tương quan tuyệt đối **1.00** với `Credit_Limit`. Về mặt toán học, `Avg_Open_To_Buy = Credit_Limit - Revolving_Bal`. Việc giữ cả hai không mang lại thêm thông tin mà gây nhiễu và lãng phí tài nguyên tính toán.\n",
    "2.  **`Gender`**: Trong biểu đồ tần suất được so với `Attrition_Flag`, cột định dang này có tần suất khá giống nhau ở cả hai giá trị M (nam giới) và F (nữ giới) và cũng có tương quan Cramér's V khá thấp với `Attriton_Flag`(**0.01**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1613d1",
   "metadata": {},
   "source": [
    "## III. Chuẩn hóa cột đặc trưng Attrition_Flag và các cột định danh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28624870",
   "metadata": {},
   "source": [
    "\n",
    "- Ta sẽ xử lí một số cột danh trước khi chuẩn hóa: \n",
    "1.  **`Card_Category`**: Vì số lượng thẻ `Blue` chiếm phần lớn nên ta sẽ gộp nhóm (Binning) tất cả các thẻ còn lại (`Sliver`, `Gold`, `Plantinum`) và chuyển hóa thành `0` (Không phải thẻ Blue) và `1`(Có thẻ Blue).\n",
    "2. **`Marital status`**: Ta sẽ gộp 2 cột `Divorced` và `Single` vì xét theo logic thì nó vẫn có chung một ý nghĩa là hiện tại vẫn chưa có hôn nhân.\n",
    "- Sau đó ta sẽ áp dụng các thuật toán để chuẩn hóa các cột:\n",
    "1. `One-hot encoding` cho các cột định danh có giá trị Unknown (Vì giá trị này vẫn có tỉ lệ từ `7 - 15%` trong các cột) gồm `Education_Level, Income_Category và Marital_Status`\n",
    "2. `Binary encoding` cho cột `Attrition_Flag và Card_Category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb3eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_np(col):\n",
    "    uniq = np.unique(col)\n",
    "    return (col[:, None] == uniq).astype(np.int8), uniq\n",
    "\n",
    "card_col = data[:, dict_data['Card_Category']]\n",
    "card_col = (card_col == 'Blue').astype(np.int8)\n",
    "\n",
    "attrition_col = data[:, dict_data['Attrition_Flag']]\n",
    "attrition_col = (attrition_col == 'Existing Customer').astype(np.int8)\n",
    "\n",
    "marital_col = data[:, dict_data['Marital_Status']]\n",
    "mapped_marital = np.where(\n",
    "    np.isin(marital_col, [\"Divorced\", \"Single\"]), \n",
    "    \"NotMarried\", \n",
    "    marital_col\n",
    ")\n",
    "marital_ohe, marital_uniques = one_hot_np(mapped_marital)\n",
    "\n",
    "education_col = data[:, dict_data['Education_Level']]\n",
    "education_ohe, education_uniques = one_hot_np(education_col)\n",
    "\n",
    "income_col = data[:, dict_data['Income_Category']]\n",
    "income_ohe, income_uniques = one_hot_np(income_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9065e8",
   "metadata": {},
   "source": [
    "## IV. Điều chỉnh kích thước cho các cột có giá trị số"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23513e32",
   "metadata": {},
   "source": [
    "### IV.1. Áp dụng Z-score Normalization cho nhóm biến phân phối chuẩn\n",
    "\n",
    "Đối với những cột dữ liệu có phân phối tương đối ổn định, ít bị lệch (non-skewed) hoặc có dạng gần với phân phối chuẩn (Gaussian), ta áp dụng phương pháp chuẩn hóa Z-score (Standardization). Phương pháp này giúp đưa các biến về cùng một thang đo thống kê chung, loại bỏ sự khác biệt về đơn vị đo lường (scale invariance) giữa các đặc trưng:\n",
    "\n",
    "* `Customer_Age`\n",
    "* `Dependent_count`\n",
    "* `Total_Relationship_Count`\n",
    "* `Months_Inactive_12_mon`\n",
    "* `Contacts_Count_12_mon`\n",
    "* `Total_Amt_Chng_Q4_Q1`\n",
    "* `Total_Ct_Chng_Q4_Q1`\n",
    "* `Months_on_book`\n",
    "\n",
    "**Cơ sở toán học:**\n",
    "\n",
    "Giá trị được chuyển đổi bằng cách lấy hiệu số giữa giá trị gốc và giá trị trung bình, sau đó chia cho độ lệch chuẩn. Quá trình này tập trung dữ liệu về gốc tọa độ 0 và co giãn độ phân tán sao cho độ lệch chuẩn bằng 1.\n",
    "\n",
    "$$x_{scaled} = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Trong đó:\n",
    "* $x$: Giá trị gốc ban đầu.\n",
    "* $\\mu$: Giá trị trung bình (mean) của toàn bộ cột dữ liệu.\n",
    "* $\\sigma$: Độ lệch chuẩn (standard deviation) của toàn bộ cột dữ liệu.\n",
    "* $x_{scaled}$: Giá trị sau khi đã được chuẩn hóa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b2d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_score = [\n",
    "    'Customer_Age', 'Dependent_count', 'Total_Relationship_Count',\n",
    "    'Months_Inactive_12_mon', 'Contacts_Count_12_mon',\n",
    "    'Total_Amt_Chng_Q4_Q1', 'Total_Ct_Chng_Q4_Q1',\n",
    "    'Months_on_book'\n",
    "]\n",
    "\n",
    "def zscore(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "numerical_score_col = np.empty((data.shape[0], 0))\n",
    "\n",
    "for col in numerical_score:\n",
    "    col_data = data[:, dict_data[col]].astype(float)\n",
    "    col_z = zscore(col_data)\n",
    "    numerical_score_col = np.hstack((numerical_score_col, col_z.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59def3c",
   "metadata": {},
   "source": [
    "### Tạo cột mới: Avg_Total_Trans\n",
    "\n",
    "```\n",
    "Avg_Total_Trans = Total_Trans_Amt / Total_Trans_Ct\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b10a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_amt = data[:, dict_data['Total_Trans_Amt']].astype(float)\n",
    "trans_ct = data[:, dict_data['Total_Trans_Ct']].astype(float)\n",
    "average_total = trans_amt / trans_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf951c",
   "metadata": {},
   "source": [
    "### IV.2. Áp dụng Log Scaling cho nhóm biến phân phối lệch phải, có giá trị lớn\n",
    "\n",
    "Đối với những cột dữ liệu có dải giá trị rộng và biểu đồ phân phối bị lệch hẳn về phía bên phải (right-skewed), ta áp dụng phương pháp biến đổi Logarit. Phương pháp này giúp co hẹp khoảng giá trị, đưa phân phối về dạng cân đối hơn và giảm thiểu tác động của các giá trị ngoại lai (outliers):\n",
    "\n",
    "* `Credit_Limit`\n",
    "* `Avg_Open_To_Buy`\n",
    "* `Total_Revolving_Bal`\n",
    "* `Avg_Total_Trans` (cột mới tạo)\n",
    "\n",
    "**Cơ sở toán học:**\n",
    "\n",
    "Giá trị được chuyển đổi bằng cách lấy logarit tự nhiên của (giá trị gốc + 1). Việc cộng thêm 1 vào công thức là bắt buộc để đảm bảo tính toán học trong trường hợp dữ liệu đầu vào có giá trị bằng 0 (vì logarit của 0 không xác định).\n",
    "\n",
    "$$x_{log} = \\ln(1 + x)$$\n",
    "\n",
    "Trong đó:\n",
    "* $x$: Giá trị gốc ban đầu.\n",
    "* $1$: Hằng số cộng thêm để tránh lỗi toán học khi $x = 0$.\n",
    "* $\\ln$: Logarit tự nhiên (cơ số $e$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bdeb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_log = [\n",
    "    'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy',\n",
    "    'Avg_Total_Trans']\n",
    "\n",
    "def log_scale(x):\n",
    "    return np.log1p(x)\n",
    "\n",
    "numerical_log_col = np.empty((data.shape[0], 0))\n",
    "for col in numerical_log:\n",
    "    if col == 'Avg_Total_Trans':\n",
    "        col_data = average_total\n",
    "    else:\n",
    "        col_data = data[:, dict_data[col]].astype(float)\n",
    "    col_log = log_scale(col_data)\n",
    "    numerical_log_col = np.hstack((numerical_log_col, col_log.reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587aca2e",
   "metadata": {},
   "source": [
    "### IV.3. Sử dụng Min-Max Scaling cho biến có phạm vi [0, 1]\n",
    "\n",
    "Đối với cột dữ liệu đã có dải giá trị nằm sẵn trong khoảng từ 0 đến 1 nhưng phân phối không đều (thiên lệch về 0), ta sử dụng phương pháp Min-Max Scaling. Việc này nhằm đảm bảo tính nhất quán tuyệt đối về biên độ dữ liệu với các biến khác sau khi chuẩn hóa, giữ nguyên tỉ lệ khoảng cách giữa các giá trị:\n",
    "\n",
    "* `Avg_Utilization_Ratio` (Giá trị từ 0 đến 1, phân phối lệch về 0)\n",
    "\n",
    "**Cơ sở toán học:**\n",
    "\n",
    "Phép biến đổi tuyến tính giúp quy đổi dữ liệu về đoạn [0, 1] dựa trên hai giá trị cực trị (nhỏ nhất và lớn nhất) của tập dữ liệu:\n",
    "\n",
    "$$x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n",
    "Trong đó:\n",
    "* $x$: Giá trị gốc ban đầu.\n",
    "* $x_{min}$: Giá trị nhỏ nhất của cột dữ liệu.\n",
    "* $x_{max}$: Giá trị lớn nhất của cột dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b251f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "util_col = data[:, dict_data['Avg_Utilization_Ratio']].astype(float)\n",
    "util_mm = minmax(util_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd1bec",
   "metadata": {},
   "source": [
    "## V. Lưu thành các cột đã xử lí vào file mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fd652e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_matrix = np.column_stack([\n",
    "    attrition_col,          # Target\n",
    "    card_col,               # Binary Card\n",
    "    marital_ohe,            # One hot\n",
    "    education_ohe,\n",
    "    income_ohe,\n",
    "    numerical_score_col,                 # Z-score\n",
    "    numerical_log_col,               # Log-scaled\n",
    "    util_mm                 # MinMax\n",
    "])\n",
    "\n",
    "headers = []\n",
    "\n",
    "headers.append(\"Attrition_Flag\")\n",
    "headers.append(\"Is_Blue_Card\")\n",
    "\n",
    "headers += [f\"Marital_{u}\" for u in marital_uniques]\n",
    "headers += [f\"Education_{u}\" for u in education_uniques]\n",
    "headers += [f\"Income_{u}\" for u in income_uniques]\n",
    "\n",
    "headers += [f\"{c}_zscore\" for c in numerical_score]\n",
    "headers += [f\"{c}_log\" for c in numerical_log]\n",
    "\n",
    "headers.append(\"Avg_Utilization_Ratio_minmax\")\n",
    "\n",
    "header_line = \",\".join(headers)\n",
    "np.savetxt(\n",
    "    \"../data/BankChurners_preprocessed.csv\",\n",
    "    final_matrix,\n",
    "    delimiter=\",\",\n",
    "    header=header_line,\n",
    "    comments=\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
