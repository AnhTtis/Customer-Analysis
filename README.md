# **Customer Churn Prediction â€” Bank Churners Dataset**

Dá»± Ä‘oÃ¡n kháº£ nÄƒng rá»i Ä‘i cá»§a khÃ¡ch hÃ ng tháº» tÃ­n dá»¥ng báº±ng phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y cÃ i Ä‘áº·t báº±ng **NumPy**.

---

# **Má»¥c lá»¥c**

- [I. Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
  - [I.1. MÃ´ táº£ bÃ i toÃ¡n](#i1--mÃ´-táº£-bÃ i-toÃ¡n)
  - [I.2 Äá»™ng lá»±c vÃ  á»©ng dá»¥ng thá»±c táº¿](#ii2-Ä‘á»™ng-lá»±c-vÃ -á»©ng-dá»¥ng-thá»±c-táº¿)
  - [I.3 Má»¥c tiÃªu cá»¥ thá»ƒ](#ii3-má»¥c-tiÃªu-cá»¥-thá»ƒ)
- [Dataset](#dataset)
  - [II.1 Nguá»“n dá»¯ liá»‡u](#ii1-nguá»“n-dá»¯-liá»‡u)
  - [II.2 KÃ­ch thÆ°á»›c vÃ  Ä‘áº·c Ä‘iá»ƒm](#ii2-kÃ­ch-thÆ°á»›c-vÃ -Ä‘áº·c-Ä‘iá»ƒm)
  - [II. 3 MÃ´ táº£ cÃ¡c feature](#ii3-mÃ´-táº£-cÃ¡c-features)
- [Method](#method)
4. [Installation & Setup](#installation--setup)
5. [Usage](#usage)
6. [Results](#results)
7. [Project Structure](#project-structure)
8. [Challenges & Solutions](#challenges--solutions)
9. [Future Improvements](#future-improvements)
10. [Contributors](#contributors)
11. [License](#license)

---

# I. **Giá»›i thiá»‡u**

## I.1  MÃ´ táº£ bÃ i toÃ¡n

BÃ i toÃ¡n yÃªu cáº§u dá»± Ä‘oÃ¡n khÃ¡ch hÃ ng tháº» tÃ­n dá»¥ng **cÃ³ rá»i Ä‘i** (`attrition`) hay khÃ´ng dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng hÃ nh vi vÃ  thÃ´ng tin tÃ i chÃ­nh. ÄÃ¢y lÃ  bÃ i toÃ¡n **phÃ¢n loáº¡i nhá»‹ phÃ¢n** (`binary classification`)  vá»›i má»¥c tiÃªu tá»‘i Æ°u hÃ³a chiáº¿n lÆ°á»£c giá»¯ chÃ¢n khÃ¡ch hÃ ng.

## II.2 Äá»™ng lá»±c vÃ  á»©ng dá»¥ng thá»±c táº¿

* Khi pháº£i Ä‘Æ°a ra chÃ­nh sÃ¡ch hoáº·c phÆ°Æ¡ng Ã¡n trong viá»‡c giá»¯ láº¡i khÃ¡ch hÃ nh tiá»m nÄƒng hay tÃ¬m kiáº¿m khÃ¡ch hÃ ng má»›i, ta nháº­n tháº¥y chi phÃ­ giá»¯ khÃ¡ch hÃ ng tháº¥p hÆ¡n chi phÃ­ tÃ¬m khÃ¡ch má»›i nhÆ°ng pháº£i biáº¿t Ä‘Æ°á»£c nhá»¯ng khÃ¡ch hÃ ng nÃ o cÃ²n á»Ÿ láº¡i.

* CÃ³ nhá»¯ng chÃ­nh sÃ¡ch giÃºp giá»¯ láº¡i nhiá»u khÃ¡ch hÃ ng Ä‘á»ƒ giáº£m thiá»ƒu rá»§i ro rá»i bá» dá»‹ch vá»¥, giÃºp tÄƒng lá»£i nhuáº­n.

* Dá»± bÃ¡o Ä‘Æ°á»£c xu hÆ°á»›ng cá»§a khÃ¡ch hÃ ng giÃºp ngÃ¢n hÃ ng quyáº¿t Ä‘á»‹nh chiáº¿n lÆ°á»£c marketing há»£p lÃ½.

## II.3 Má»¥c tiÃªu cá»¥ thá»ƒ

* KhÃ¡m phÃ¡ dá»¯ liá»‡u (EDA) Ä‘á»ƒ hiá»ƒu hÃ nh vi khÃ¡ch hÃ ng. Äá»“ng thá»i, Ä‘Æ°a ra má»™t sá»‘ khÃ¡m phÃ¡ thÃº vá»‹ (insights - náº¿u cÃ³) vá» dá»¯ liá»‡u

* Tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÃ  chuáº©n hÃ³a dá»¯ liá»‡u Ä‘á»ƒ chuáº©n bá»‹ cho cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y.

* XÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y báº±ng **NumPy** (khÃ´ng dÃ¹ng thÆ° viá»‡n ML):

  * Logistic Regression
  * Gaussian Naive Bayes
  * KNN

* XÃ¢y dá»±ng má»™t sá»‘ hÃ m Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh

---

# II. **Dataset**

## II.1 Nguá»“n dá»¯ liá»‡u

* Kaggle: [Credit Card Customers Dataset](https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers)

* TÃªn file: `BankChurners.csv` (Trong folder data)

* Giáº¥y phÃ©p: [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)

## II.2 KÃ­ch thÆ°á»›c vÃ  Ä‘áº·c Ä‘iá»ƒm

* Sá»‘ dÃ²ng: **10,127**
* Sá»‘ cá»™t: **23**
* NhÃ£n cáº§n dá»± Ä‘oÃ¡n: **Attrition_Flag** (Existing Customer / Attrited Customer)
* 2 cá»™t cuá»‘i (`Naive_Bayes_1`, `Naive_Bayes_2`) bá»‹ loáº¡i bá» theo khuyáº¿n nghá»‹ cá»§a tÃ¡c giáº£ dataset.

## II.3 MÃ´ táº£ cÃ¡c features:

Bá»™ dá»¯ liá»‡u bao gá»“m **23 cá»™t** nhÆ° sau:

| TÃªn Cá»™t | MÃ´ Táº£ | 
| :--- | :--- | 
| `CLIENTNUM` | MÃ£ Ä‘á»‹nh danh khÃ¡ch hÃ ng (Unique ID) | 
| `Attrition_Flag` | Tráº¡ng thÃ¡i hoáº¡t Ä‘á»™ng | 
| `Customer_Age` | Äá»™ tuá»•i khÃ¡ch hÃ ng |
| `Gender` | Giá»›i tÃ­nh | 
| `Dependent_count` | Sá»‘ ngÆ°á»i phá»¥ thuá»™c | 
| `Education_Level` | TrÃ¬nh Ä‘á»™ há»c váº¥n | 
| `Marital_Status` | TÃ¬nh tráº¡ng hÃ´n nhÃ¢n |
| `Income_Category` | NhÃ³m thu nháº­p hÃ ng nÄƒm | 
| `Card_Category` | Loáº¡i tháº» tÃ­n dá»¥ng |
| `Months_on_book` | Thá»i gian gáº¯n bÃ³ vá»›i ngÃ¢n hÃ ng |
| `Total_Relationship_Count` | Tá»•ng sá»‘ sáº£n pháº©m/dá»‹ch vá»¥ sá»Ÿ há»¯u |
| `Months_Inactive_12_mon` | Sá»‘ thÃ¡ng khÃ´ng hoáº¡t Ä‘á»™ng (12 thÃ¡ng qua) |
| `Contacts_Count_12_mon` | Sá»‘ láº§n liÃªn há»‡ ngÃ¢n hÃ ng (12 thÃ¡ng qua) |
| `Credit_Limit` | Háº¡n má»©c tÃ­n dá»¥ng tá»‘i Ä‘a | 
| `Total_Revolving_Bal` | Tá»•ng dÆ° ná»£ quay vÃ²ng | 
| `Avg_Open_To_Buy` | Háº¡n má»©c kháº£ dá»¥ng trung bÃ¬nh (mua sáº¯m) | 
| `Total_Amt_Chng_Q4_Q1` | Tá»· lá»‡ thay Ä‘á»•i sá»‘ tiá»n giao dá»‹ch (Q4 vs Q1) |
| `Total_Trans_Amt` | Tá»•ng tiá»n giao dá»‹ch (12 thÃ¡ng qua) | 
| `Total_Trans_Ct` | Tá»•ng sá»‘ láº§n giao dá»‹ch (12 thÃ¡ng qua) | 
| `Total_Ct_Chng_Q4_Q1` | Tá»· lá»‡ thay Ä‘á»•i sá»‘ láº§n giao dá»‹ch (Q4 vs Q1) | 
| `Avg_Utilization_Ratio` | Tá»· lá»‡ sá»­ dá»¥ng tháº» trung bÃ¬nh | 
| `Naive_Bayes_Classifier..._1` | Káº¿t quáº£ tá»« thuáº­t toÃ¡n Naive Bayes (Gá»‘c) - Cá»™t sinh ra tá»« quÃ¡ trÃ¬nh xÃ¢y dá»±ng dá»¯ liá»‡u |
| `Naive_Bayes_Classifier..._2` | Káº¿t quáº£ tá»« thuáº­t toÃ¡n Naive Bayes (Gá»‘c) - Cá»™t sinh ra tá»« quÃ¡ trÃ¬nh xÃ¢y dá»±ng dá»¯ liá»‡u |

---

# III. **Method**

## III.1 Quy trÃ¬nh KhÃ¡m phÃ¡ dá»¯ liá»‡u
* **File trÃ¬nh bÃ y**: 01_data_exploration.ipynb trong folder notebooks
* **LÆ°u Ã½**: Trong quÃ¡ trÃ¬nh thá»±c hiá»‡n viá»‡c khÃ¡m phÃ¡ dá»¯ liá»‡u ta sáº½ xÃ¢y dá»±ng má»™t tá»« Ä‘iá»ƒn Ä‘á»ƒ chÃºng ta mapping dá»¯ liá»‡u tá»«ng cá»™t thá»‘ng qua tÃªn cá»™t
* **QuÃ¡ trÃ¬nh thá»±c hiá»‡n**: 
  - **BÆ°á»›c 1**: XÃ¡c Ä‘á»‹nh má»™t sá»‘ thÃ´ng tin cÆ¡ báº£n cá»§a `Dataset`
    - XÃ¡c Ä‘á»‹nh sá»‘ dÃ²ng vÃ  sá»‘ cá»™t cá»§a dá»¯ liá»‡u. 
    - XÃ¡c Ä‘á»‹nh tÃªn cá»§a tá»«ng cá»™t dá»¯ liá»‡u, cÃ³ bao nhiÃªu cá»™t Ä‘á»‹nh danh vÃ  bao nhiÃªu cá»™t sá»‘
    - XÃ¡c Ä‘á»‹nh khoáº£ng giÃ¡ trá»‹ cá»§a tá»«ng cá»™t: Ä‘á»‘i vá»›i cá»™t Ä‘á»‹nh danh thÃ¬ in ra cÃ¡c `cÃ¡c giÃ¡ trá»‹ riÃªng biá»‡t`, cÃ²n Ä‘á»‘i vá»›i cÃ¡c cá»™t cÃ³ giÃ¡ trá»‹ gá»“m nhiá»u sá»‘ thÃ¬ in ra `sá»‘ lá»›n nháº¥t, sá»‘ nhá» nháº¥t, sá»‘ trung bÃ¬nh, trung vá»‹ vÃ  phÆ°Æ¡ng sai`.
    - XÃ¡c Ä‘á»‹nh kiá»ƒu dá»¯ liá»‡u cá»§a tá»«ng cá»™t vÃ  kiá»ƒm tra sá»‘ lÆ°á»£ng dá»¯ liá»‡u bá»‹ thiáº¿u

  - **BÆ°á»›c 2**: Biá»ƒu diá»…n phÃ¢n phá»‘i cá»§a tá»«ng cá»™t dá»¯ liá»‡u. Äá»‘i vá»›i cÃ¡c cá»™t sá»‘ thÃ¬ dÃ¹ng `biá»ƒu Ä‘á»“ táº§n sá»‘ (Histogram)` káº¿t há»£p vá»›i `Ä‘Æ°á»ng cong máº­t Ä‘á»™ (KDE)` , cÃ²n Ä‘á»‘i vá»›i cÃ¡c cá»™t Ä‘á»‹nh danh thÃ¬ dÃ¹ng `biá»ƒu Ä‘á»“ cá»™t (Bar chart)` Ä‘á»ƒ nháº­n xÃ©t phÃ¢n phá»‘i cá»§a tá»«ng cá»™t (VÃ­ dá»¥ nhÆ°: cÃ¡c cá»™t sá»‘ thÃ¬ cÃ³ thá»ƒ cÃ³ ` PhÃ¢n phá»‘i chuáº©n`, ` PhÃ¢n phá»‘i lá»‡ch pháº£i/trÃ¡i`,v.v cÃ²n cÃ¡c cá»™t Ä‘á»‹nh danh cÃ³ thá»ƒ nháº­n biáº¿t Ä‘Æ°á»£c Ä‘á»™ lá»‡ch giá»¯a cÃ¡c thÃ nh pháº§n)

  - **BÆ°á»›c 3**: Sá»­ dá»¥ng `biá»ƒu Ä‘á»“ trÃ²n (Pie chart)` Ä‘á»ƒ hiá»ƒn thá»‹ pháº§n trÄƒm cÃ¡c giÃ¡ trá»‹ trong cÃ¡c cá»™t Ä‘á»‹nh  danh

  - **BÆ°á»›c 4**: Sá»­ dá»¥ng `biá»ƒu Ä‘á»“ há»™p` Ä‘á»ƒ so sÃ¡nh phÃ¢n phá»‘i sá»‘ liá»‡u trong cÃ¡c cá»™t giÃ¡ trá»‹ sá»‘ vá»›i cá»™t Ä‘áº·c trÆ°ng `Attrition_Flag` (Ä‘Æ°á»£c chuáº©n hÃ³a thÃ nh 0 - `Attrited Customer` vÃ  1 - `Existing Customer`)

  - **BÆ°á»›c 5:** Sá»­ dá»¥ng `Countplot (Biá»ƒu Ä‘á»“ Ä‘áº¿m táº§n suáº¥t Ä‘Æ°á»£c tÃ¬nh bÃ y dÆ°á»›i dáº¡ng biá»ƒu Ä‘á»“ thanh)` Ä‘á»ƒ so sÃ¡nh phÃ¢n phá»‘i cá»§a cÃ¡c cá»™t cÃ³ giÃ¡ trá»‹ Ä‘á»‹nh danh so vá»›i cá»™t Ä‘áº·c trÆ°ng `Attrition_Flag`

  - **BÆ°á»›c 6:** Váº½ `ma tráº­n tÆ°Æ¡ng quan (correlation matrix)` giá»¯a cÃ¡c cá»™t Ä‘á»ƒ ta cÃ³ má»™t sá»‘ insights cáº§n thiáº¿t cho quÃ¡ trÃ¬nh xá»­ lÃ­ dá»¯ liá»‡u vÃ  cÃ¢y dá»±ng model 
    - Äá»‘i vá»›i cÃ¡c cá»™t sá»‘:
      1. Chuáº©n hÃ³a cá»™t `Attrition_Flag` (`Existing Customer` &rarr; 1; `Attrited Customer` &rarr; 0)
      2. Sá»­ dá»¥ng há»‡ sá»‘ tÆ°Æ¡ng quan `Pearson` Ä‘á»ƒ tÃ­nh toÃ¡n vÃ  biá»ƒu diá»…n ma tráº­n tÆ°Æ¡ng quan (`correlation matrix`) giá»¯a cÃ¡c cá»™t cÃ³ giÃ¡ trá»‹ sá»‘ cÅ©ng nhÆ° cá»™t giÃ¡ trá»‹ Ä‘áº·c trÆ°ng `Attrition_Flag`

    - Äá»‘i vá»›i cÃ¡c cá»™t Ä‘á»‹nh danh: Sá»­ dá»¥ng há»‡ sá»‘ `CramÃ©r's V` Ä‘á»ƒ tÃ­nh toÃ¡n vÃ  biá»ƒu diá»…n ma tráº­n tÆ°Æ¡ng quan (`correlation matrix`) giá»¯a cÃ¡c cá»™t Ä‘á»‹nh danh

## III.2 Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u:
* **File trÃ¬nh bÃ y**: 02_preprocessing.ipynb trong folder notebooks
* **LÆ°u Ã½**: TrÆ°á»›c khi báº¯t Ä‘áº§u Xá»­ lÃ­ dá»¯ liá»‡u, ta cÅ©ng sáº½ xÃ¢y dá»±ng má»™t tá»« Ä‘iá»ƒn Ä‘á»ƒ chÃºng ta mapping dá»¯ liá»‡u tá»«ng cá»™t thÃ´ng qua tÃªn cá»™t giá»‘ng nhÆ° trÃªn
* **QuÃ¡ trÃ¬nh thá»±c hiá»‡n**:
  - **BÆ°á»›c 1**: Bá» nhá»¯ng cá»™t khÃ´ng quan trá»ng trong viá»‡c thiáº¿t káº¿ mÃ´ hÃ¬nh bao gá»“m   **`Avg_Open_To_Buy`** vÃ   **`Gender`** (RÃºt ra Ä‘Æ°á»£c tá»« quÃ¡ trÃ¬nh `KhÃ¡m phÃ¡ dá»¯ liá»‡u`)

  - **BÆ°á»›c 2**: Chuáº©n hÃ³a cá»™t Ä‘áº·c trÆ°ng Attrition_Flag vÃ  cÃ¡c cá»™t Ä‘á»‹nh danh. 

  - **BÆ°á»›c 3**: Sá»­ dá»¥ng Z-Score Scaling cho cÃ¡c nhÃ³m phÃ¢n phá»‘i chuáº©n

  - **BÆ°á»›c 4**:Táº¡o cá»™t má»›i: `Avg_Total_Trans`báº±ng cÃ¡ch láº¥y thÆ°Æ¡ng cá»§a phÃ©p chia `Total_Trans_Amt` vÃ  `Total_Trans_Ct`

  - **BÆ°á»›c 5:** Sá»¯ dá»¥ng Log Scaling cho nhá»¯ng cá»™t cÃ³ phÃ¢n phá»‘i lá»‡ch pháº£i, cÃ³ giÃ¡ trá»‹ lá»›n 

  - **BÆ°á»›c 6:**  Sá»­ dá»¥ng MinMax cho nhá»¯ng cá»™t Ä‘Ã£ náº±m trong pháº¡m vi [0, 1]

  - **BÆ°á»›c 7:** LÆ°u láº¡i dÆ°á»›i liá»‡u dÆ°á»›i dáº¡ng file má»›i `BankChurners_preprocessed.csv` trong file data


---

## III.3 Quy trÃ¬nh xÃ¢y dá»±ng model:
### III.3.1 Thuáº­t toÃ¡n Logistic Regression

**Äá»‹nh nghÄ©a:**
ÄÃ¢y lÃ  thuáº­t toÃ¡n há»c mÃ¡y cÃ³ giÃ¡m sÃ¡t (Supervised Learning) chuyÃªn dá»¥ng cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n (Binary Classification), Ä‘Æ°a ra dá»± Ä‘oÃ¡n dÆ°á»›i dáº¡ng xÃ¡c suáº¥t (0 hoáº·c 1).

**Quy trÃ¬nh xÃ¢y dá»±ng vÃ  tá»‘i Æ°u mÃ´ hÃ¬nh:**

QuÃ¡ trÃ¬nh huáº¥n luyá»‡n Ä‘Æ°á»£c thá»±c hiá»‡n qua cÃ¡c bÆ°á»›c láº·p (epochs) vá»›i cÆ¡ cháº¿ Gradient Descent:

**1. Khá»Ÿi táº¡o tham sá»‘ (Initialization)**
Thiáº¿t láº­p tráº¡ng thÃ¡i ban Ä‘áº§u cho mÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n:
* Trá»ng sá»‘ $w$ lÃ  vector 0 (`np.zeros`) vÃ  há»‡ sá»‘ chá»‡ch $b = 0$.

**2. QuÃ¡ trÃ¬nh Lan truyá»n xuÃ´i (Forward Propagation)**
TÃ­nh toÃ¡n dá»± Ä‘oÃ¡n xÃ¡c suáº¥t dá»±a trÃªn dá»¯ liá»‡u Ä‘áº§u vÃ o:
* **Tá»• há»£p tuyáº¿n tÃ­nh:**
    $$z = w \cdot X + b$$
* **HÃ m kÃ­ch hoáº¡t Sigmoid:**
    $$\hat{y} = \frac{1}{1 + e^{-z}}$$
* **LÆ°u Ã½ ká»¹ thuáº­t (NumPy):** Äá»ƒ Ä‘áº£m báº£o tÃ­nh á»•n Ä‘á»‹nh sá»‘ há»c vÃ  trÃ¡nh lá»—i trÃ n sá»‘ (overflow) khi tÃ­nh hÃ m mÅ© `np.exp`, giÃ¡ trá»‹ cá»§a $z$ Ä‘Æ°á»£c giá»›i háº¡n trong khoáº£ng [-250, 250] báº±ng hÃ m `np.clip`.

**3. TÃ­nh toÃ¡n Gradient (Backward Propagation)**
TÃ­nh Ä‘áº¡o hÃ m cá»§a hÃ m máº¥t mÃ¡t Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÆ°á»›ng Ä‘iá»u chá»‰nh tham sá»‘. Viá»‡c tÃ­nh toÃ¡n Ä‘Æ°á»£c **vector hÃ³a** hoÃ n toÃ n báº±ng `np.dot` giÃºp tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½ so vá»›i vÃ²ng láº·p thÃ´ng thÆ°á»ng:
* **Gradient cá»§a trá»ng sá»‘ $w$:**
    $$dw = \frac{1}{m} X^T (\hat{y} - y)$$
* **Gradient cá»§a há»‡ sá»‘ $b$:**
    $$db = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})$$

**4. Cáº­p nháº­t tham sá»‘ (Parameter Update)**
Äiá»u chá»‰nh tham sá»‘ ngÆ°á»£c hÆ°á»›ng Gradient Ä‘á»ƒ giáº£m thiá»ƒu sai sá»‘, vá»›i $\alpha$ lÃ  tá»‘c Ä‘á»™ há»c (learning rate):
* $w_{new} = w_{old} - \alpha \times dw$
* $b_{new} = b_{old} - \alpha \times db$

**5. Dá»± Ä‘oÃ¡n (Prediction)**
Sau khi tá»‘i Æ°u hÃ³a $w$ vÃ  $b$, mÃ´ hÃ¬nh Ä‘Æ°a ra káº¿t quáº£ phÃ¢n loáº¡i dá»±a trÃªn ngÆ°á»¡ng xÃ¡c suáº¥t (Threshold):
* Náº¿u $\hat{y} > 0.5 \Rightarrow$ Lá»›p 1.
* NgÆ°á»£c láº¡i $\Rightarrow$ Lá»›p 0.

---

### III.3.2 Thuáº­t toÃ¡n K-Nearest Neighbors (KNN)

**Äá»‹nh nghÄ©a:**
ÄÃ¢y lÃ  thuáº­t toÃ¡n thuá»™c nhÃ³m **Há»c lÆ°á»i (Lazy Learning)** vÃ  **Phi tham sá»‘ (Non-parametric)** dÃ¹ng cho bÃ i toÃ¡n phÃ¢n loáº¡i. KhÃ¡c vá»›i cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y thÃ´ng thÆ°á»ng, KNN khÃ´ng huáº¥n luyá»‡n Ä‘á»ƒ tÃ¬m ra bá»™ trá»ng sá»‘ cá»‘ Ä‘á»‹nh mÃ  trá»±c tiáº¿p ghi nhá»› toÃ n bá»™ dá»¯ liá»‡u. Quyáº¿t Ä‘á»‹nh phÃ¢n loáº¡i dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a dá»¯ liá»‡u má»›i vÃ  dá»¯ liá»‡u Ä‘Ã£ biáº¿t.

**Quy trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh:**

**1. Ghi nhá»› dá»¯ liá»‡u (Training Phase)**
MÃ´ hÃ¬nh chá»‰ thá»±c hiá»‡n viá»‡c lÆ°u trá»¯ dá»¯ liá»‡u huáº¥n luyá»‡n (`X_train`, `y_train`) vÃ o bá»™ nhá»› mÃ  khÃ´ng thá»±c hiá»‡n báº¥t ká»³ phÃ©p tÃ­nh toÃ¡n nÃ o táº¡i bÆ°á»›c nÃ y.

**2. Dá»± Ä‘oÃ¡n (Prediction Phase)**
Khi tiáº¿p nháº­n dá»¯ liá»‡u Ä‘áº§u vÃ o má»›i, thuáº­t toÃ¡n thá»±c hiá»‡n chuá»—i xá»­ lÃ½ sau:

* **TÃ­nh toÃ¡n khoáº£ng cÃ¡ch (Vectorized Distance Calculation):**
    Má»¥c tiÃªu lÃ  tÃ­nh khoáº£ng cÃ¡ch Euclidean giá»¯a Ä‘iá»ƒm dá»¯ liá»‡u má»›i vÃ  toÃ n bá»™ táº­p dá»¯ liá»‡u huáº¥n luyá»‡n. Äá»ƒ tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ xá»­ lÃ½ trÃªn ma tráº­n lá»›n, thay vÃ¬ dÃ¹ng vÃ²ng láº·p, Ä‘oáº¡n code sá»­ dá»¥ng háº±ng Ä‘áº³ng thá»©c vector hÃ³a:
    $$(A - B)^2 = A^2 + B^2 - 2AB$$
    
    CÃ´ng thá»©c triá»ƒn khai:
    $$Distance = \sqrt{X_{new}^2 + X_{train}^2 - 2(X_{new} \cdot X_{train}^T)}$$
    
    Trong Ä‘Ã³, tÃ­ch vÃ´ hÆ°á»›ng ($2AB$) Ä‘Ã³ng vai trÃ² cá»‘t lÃµi giÃºp táº­n dá»¥ng sá»©c máº¡nh tÃ­nh toÃ¡n ma tráº­n cá»§a NumPy.

* **TÃ¬m kiáº¿m lÃ¡ng giá»ng (Nearest Neighbor Search):**
    Sá»­ dá»¥ng `np.argsort` Ä‘á»ƒ sáº¯p xáº¿p khoáº£ng cÃ¡ch tá»« nhá» Ä‘áº¿n lá»›n, sau Ä‘Ã³ trÃ­ch xuáº¥t $k$ chá»‰ sá»‘ (index) cÃ³ khoáº£ng cÃ¡ch nhá» nháº¥t tÆ°Æ¡ng á»©ng vá»›i $k$ lÃ¡ng giá»ng gáº§n nháº¥t.

* **Báº§u chá»n Ä‘a sá»‘ (Majority Voting):**
    XÃ¡c Ä‘á»‹nh nhÃ£n cá»§a dá»¯ liá»‡u má»›i dá»±a trÃªn nguyÃªn táº¯c "thiá»ƒu sá»‘ phá»¥c tÃ¹ng Ä‘a sá»‘" trong táº­p $k$ lÃ¡ng giá»ng. Sá»­ dá»¥ng `np.bincount` Ä‘á»ƒ Ä‘áº¿m táº§n suáº¥t xuáº¥t hiá»‡n cá»§a cÃ¡c nhÃ£n vÃ  `argmax` Ä‘á»ƒ chá»n ra nhÃ£n cÃ³ sá»‘ phiáº¿u cao nháº¥t.

---

### III.3.3 Thuáº­t toÃ¡n Gaussian Naive Bayes

* **Äá»‹nh nghÄ©a**
ÄÃ¢y lÃ  thuáº­t toÃ¡n phÃ¢n loáº¡i dá»±a trÃªn **Äá»‹nh lÃ½ Bayes** vá»›i giáº£ Ä‘á»‹nh ráº±ng cÃ¡c Ä‘áº·c trÆ°ng (features) Ä‘á»™c láº­p vá»›i nhau vÃ  tuÃ¢n theo phÃ¢n phá»‘i chuáº©n (Gaussian distribution).

* **Quy trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh**

**1. Huáº¥n luyá»‡n (Training Phase - Thá»‘ng kÃª dá»¯ liá»‡u)**
Thay vÃ¬ tá»‘i Æ°u hÃ³a hÃ m máº¥t mÃ¡t, mÃ´ hÃ¬nh "há»c" báº±ng cÃ¡ch tÃ­nh toÃ¡n trá»±c tiáº¿p cÃ¡c tham sá»‘ thá»‘ng kÃª cho tá»«ng lá»›p dá»¯ liá»‡u:
* **Tham sá»‘ phÃ¢n phá»‘i:** TÃ­nh giÃ¡ trá»‹ trung bÃ¬nh ($\mu$) vÃ  phÆ°Æ¡ng sai ($\sigma^2$) cho tá»«ng Ä‘áº·c trÆ°ng cá»§a má»—i lá»›p.
* **XÃ¡c suáº¥t tiÃªn nghiá»‡m ($P(Class)$):** TÃ­nh tá»· lá»‡ xuáº¥t hiá»‡n cá»§a má»—i lá»›p trong táº­p huáº¥n luyá»‡n.
* **á»”n Ä‘á»‹nh sá»‘ há»c:** Cá»™ng thÃªm má»™t háº±ng sá»‘ cá»±c nhá» (`1e-9`) vÃ o phÆ°Æ¡ng sai Ä‘á»ƒ lÃ m mÆ°á»£t (smoothing), ngÄƒn cháº·n lá»—i chia cho 0.

**2. Dá»± Ä‘oÃ¡n (Prediction Phase - Log-Likelihood)**
Äá»ƒ trÃ¡nh lá»—i trÃ n sá»‘ dÆ°á»›i (numerical underflow) khi nhÃ¢n nhiá»u giÃ¡ trá»‹ xÃ¡c suáº¥t nhá», thuáº­t toÃ¡n thá»±c hiá»‡n tÃ­nh toÃ¡n trong khÃ´ng gian Logarit káº¿t há»£p vá»›i ká»¹ thuáº­t **Broadcasting** cá»§a NumPy Ä‘á»ƒ xá»­ lÃ½ song song trÃªn ma tráº­n 3 chiá»u (Samples x Classes x Features):

* **TÃ­nh Log-Likelihood:**
  Äá»™ "khá»›p" cá»§a dá»¯ liá»‡u má»›i vá»›i phÃ¢n phá»‘i chuáº©n cá»§a tá»«ng lá»›p Ä‘Æ°á»£c tÃ­nh theo cÃ´ng thá»©c:
  $$\log P(x|c) = -\frac{1}{2} \sum \left( \log(2\pi\sigma_c^2) + \frac{(x - \mu_c)^2}{\sigma_c^2} \right)$$
  *(Bao gá»“m tá»•ng cá»§a pháº§n log máº«u sá»‘ chuáº©n hÃ³a vÃ  khoáº£ng cÃ¡ch Mahalanobis bÃ¬nh phÆ°Æ¡ng).*

* **Quyáº¿t Ä‘á»‹nh phÃ¢n loáº¡i (Maximum A Posteriori):**
  Ãp dá»¥ng Ä‘á»‹nh lÃ½ Bayes báº±ng cÃ¡ch cá»™ng Log-likelihood vá»›i Log xÃ¡c suáº¥t tiÃªn nghiá»‡m vÃ  chá»n lá»›p cÃ³ giÃ¡ trá»‹ lá»›n nháº¥t:
  $$\hat{y} = \text{argmax} \left( \log P(x|c) + \log P(c) \right)$$

DÆ°á»›i Ä‘Ã¢y lÃ  pháº§n tÃ³m táº¯t ngáº¯n gá»n, sÃºc tÃ­ch nhÆ°ng bao hÃ m Ä‘áº§y Ä‘á»§ cÃ¡c Ã½ tÆ°á»Ÿng ká»¹ thuáº­t quan trá»ng báº¡n Ä‘Ã£ cung cáº¥p, Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng chuáº©n Ä‘á»ƒ Ä‘Æ°a vÃ o má»¥c III.4 cá»§a README:


### III.3.4 Chiáº¿n lÆ°á»£c ÄÃ¡nh giÃ¡ & Kiá»ƒm thá»­ MÃ´ hÃ¬nh

Äá»ƒ Ä‘áº£m báº£o káº¿t quáº£ Ä‘Ã¡nh giÃ¡ khÃ¡ch quan vÃ  tá»‘i Æ°u hÃ³a hiá»‡u nÄƒng mÃ´ hÃ¬nh, quy trÃ¬nh kiá»ƒm thá»­ Ä‘Æ°á»£c xÃ¢y dá»±ng cháº·t cháº½ thÃ´ng qua 3 thÃ nh pháº§n chÃ­nh:

#### III.3.4.1 Ká»¹ thuáº­t K-Fold Cross-Validation
Thay vÃ¬ chá»‰ chia dá»¯ liá»‡u má»™t láº§n (Train/Test split truyá»n thá»‘ng), ta Ã¡p dá»¥ng **K-Fold** Ä‘á»ƒ giáº£m thiá»ƒu phÆ°Æ¡ng sai vÃ  Ä‘Ã¡nh giÃ¡ Ä‘á»™ á»•n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh:
1.  **XÃ¡o trá»™n (Shuffle):** Äáº£m báº£o tÃ­nh ngáº«u nhiÃªn, phÃ¡ vá»¡ thá»© tá»± sáº¯p xáº¿p gá»‘c cá»§a dá»¯ liá»‡u.
2.  **Chia & Xoay vÃ²ng:** Dá»¯ liá»‡u Ä‘Æ°á»£c chia thÃ nh $k$ pháº§n. Quy trÃ¬nh láº·p $k$ láº§n, má»—i láº§n chá»n má»™t pháº§n lÃ m táº­p Test (Validation) vÃ  pháº§n cÃ²n láº¡i lÃ m táº­p Train.
3.  **Lá»£i Ã­ch:** Äáº£m báº£o 100% dá»¯ liá»‡u Ä‘á»u Ä‘Æ°á»£c kiá»ƒm thá»­ vÃ  mÃ´ hÃ¬nh khÃ´ng bá»‹ "há»c váº¹t" (overfitting) trÃªn má»™t táº­p máº«u cá»¥ thá»ƒ.

#### III.4.2 Quy trÃ¬nh váº­n hÃ nh (`evaluate_models`)
HÃ m quáº£n lÃ½ luá»“ng Ä‘Ã¡nh giÃ¡ tuÃ¢n thá»§ nghiÃªm ngáº·t nguyÃªn táº¯c **chá»‘ng rÃ² rá»‰ dá»¯ liá»‡u (Data Leakage Prevention)**:
* **BÆ°á»›c 1 - TÃ¡ch dá»¯ liá»‡u:** Táº¡i má»—i vÃ²ng láº·p K-Fold, dá»¯ liá»‡u Ä‘Æ°á»£c chia thÃ nh `Train_fold` vÃ  `Test_fold`.
* **BÆ°á»›c 2 - Xá»­ lÃ½ máº¥t cÃ¢n báº±ng:** HÃ m `oversample_minority` **CHá»ˆ Ä‘Æ°á»£c Ã¡p dá»¥ng trÃªn `Train_fold`**. Táº­p `Test_fold` Ä‘Æ°á»£c giá»¯ nguyÃªn báº£n Ä‘á»ƒ pháº£n Ã¡nh Ä‘Ãºng thá»±c táº¿.
* **BÆ°á»›c 3 - Tá»•ng há»£p:** Káº¿t quáº£ cá»§a $k$ láº§n cháº¡y Ä‘Æ°á»£c tÃ­nh trung bÃ¬nh (`np.mean`) Ä‘á»ƒ Ä‘Æ°a ra con sá»‘ hiá»‡u nÄƒng cuá»‘i cÃ¹ng Ä‘Ã¡ng tin cáº­y nháº¥t.

#### III.3.4.3 CÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ (Metrics)
Dá»±a trÃªn **Ma tráº­n nháº§m láº«n (Confusion Matrix)** vá»›i cÃ¡c yáº¿u tá»‘ TP (DÆ°Æ¡ng tÃ­nh tháº­t), FP (DÆ°Æ¡ng tÃ­nh giáº£) vÃ  FN (Ã‚m tÃ­nh giáº£), hiá»‡u nÄƒng mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘o lÆ°á»ng qua:

* **Precision (Äá»™ chÃ­nh xÃ¡c dá»± bÃ¡o dÆ°Æ¡ng):** Tá»‰ lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trong cÃ¡c trÆ°á»ng há»£p mÃ´ hÃ¬nh bÃ¡o lÃ  Positive.
    $$P = \frac{TP}{TP + FP}$$
* **Recall (Äá»™ nháº¡y):** Kháº£ nÄƒng mÃ´ hÃ¬nh phÃ¡t hiá»‡n Ä‘Æ°á»£c bao nhiÃªu % trÆ°á»ng há»£p Positive thá»±c táº¿.
    $$R = \frac{TP}{TP + FN}$$
* **F1-Score:** Trung bÃ¬nh Ä‘iá»u hÃ²a giá»¯a Precision vÃ  Recall, lÃ  chá»‰ sá»‘ quan trá»ng nháº¥t Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sá»± cÃ¢n báº±ng cá»§a mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u lá»‡ch.
    $$F1 = 2 \times \frac{P \times R}{P + R}$$

# **Installation & Setup**

```bash
git clone https://github.com/AnhTtis/Customer-Analysis
cd Customer-Analysis
pip install -r requirements.txt
```

---

# **Usage**

## Cháº¡y tá»«ng notebook

* `01_data_exploration.ipynb` â€” phÃ¢n tÃ­ch dá»¯ liá»‡u
* `02_preprocessing.ipynb` â€” xá»­ lÃ½ dá»¯ liá»‡u
* `03_modelling.ipynb` â€” huáº¥n luyá»‡n & Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
---

# ğŸ“ˆ **Results**

### Metrics Ä‘áº¡t Ä‘Æ°á»£c (tÃ¹y mÃ´ hÃ¬nh)

* Accuracy
* Precision
* Recall
* F1-score
* Confusion Matrix

### Trá»±c quan hÃ³a

* Biá»ƒu Ä‘á»“ phÃ¢n phá»‘i churn
* Ma tráº­n tÆ°Æ¡ng quan
* Histogram cá»§a cÃ¡c biáº¿n quan trá»ng
* Biá»ƒu Ä‘á»“ ROC

### So sÃ¡nh mÃ´ hÃ¬nh

* Logistic Regression á»•n Ä‘á»‹nh vÃ  chÃ­nh xÃ¡c.
* Naive Bayes nhanh nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c tháº¥p hÆ¡n.
* KNN phÃ¹ há»£p nhÆ°ng chi phÃ­ dá»± Ä‘oÃ¡n cao.

*(Báº¡n cÃ³ thá»ƒ gá»­i káº¿t quáº£ cá»¥ thá»ƒ Ä‘á»ƒ mÃ¬nh chÃ¨n vÃ o báº£ng.)*

---

# ğŸ—‚ï¸ **Project Structure**

```text
project/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ BankChurners.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ BankChurners_preprocessed.csv
|â”€â”€ notebooks/
    â”œâ”€â”€ 01_data_exploration.ipynb
    â”œâ”€â”€ 02_preprocessing.ipynb
    â””â”€â”€ 03_modelling.ipynb

```

---

# ğŸ§© **Challenges & Solutions**

### ğŸ”¹ KhÃ³ khÄƒn khi dÃ¹ng NumPy

* KhÃ´ng cÃ³ thÆ° viá»‡n ML â†’ pháº£i tá»± viáº¿t toÃ n bá»™ mÃ´ hÃ¬nh.
* Dá»… gáº·p lá»—i overflow á»Ÿ Logistic Regression.
* KNN tá»‘n thá»i gian trÃªn dataset lá»›n.
* Viá»‡c vector hÃ³a khÃ³ vá»›i ngÆ°á»i má»›i.

### ğŸ”¹ CÃ¡ch giáº£i quyáº¿t

* DÃ¹ng `np.clip` Ä‘á»ƒ trÃ¡nh overflow.
* DÃ¹ng log probability cho Naive Bayes.
* Tá»‘i Æ°u KNN báº±ng broadcasting.
* Loáº¡i bá» má»i vÃ²ng láº·p, chuyá»ƒn sang vectorization.

---

# ğŸš€ **Future Improvements**

* Thá»­ thÃªm mÃ´ hÃ¬nh nÃ¢ng cao: Random Forest, XGBoost.
* DÃ¹ng PCA giáº£m chiá»u dá»¯ liá»‡u.
* XÃ¢y dá»±ng dashboard báº±ng Streamlit.
* Tá»‘i Æ°u Logistic Regression báº±ng Adam optimizer.

---

# ğŸ‘¥ **Contributors**

| Name                   | Role   | Contact                                                  |
| ---------------------- | ------ | -------------------------------------------------------- |
| **Nguyá»…n Há»¯u Anh TrÃ­** | Author | [https://github.com/AnhTtis](https://github.com/AnhTtis) |

---

# ğŸ“„ **License â€” MIT License**

```
MIT License

Copyright (c) 2025 AnhTtis

Permission is hereby granted, free of charge, to any person obtaining a copy...
```

---

# âœ… HOÃ€N Táº¤T

Náº¿u báº¡n muá»‘n:
âœ” ThÃªm hÃ¬nh áº£nh káº¿t quáº£ â†’ gá»­i áº£nh hoáº·c mÃ´ táº£ â†’ mÃ¬nh chÃ¨n vÃ o.
âœ” ThÃªm báº£ng Ä‘iá»ƒm (Accuracy, F1) â†’ gá»­i sá»‘ liá»‡u â†’ mÃ¬nh hoÃ n thiá»‡n.

Chá»‰ cáº§n nÃ³i **â€œupdate README pháº§n â€¦â€**, mÃ¬nh cáº­p nháº­t ngay.
